---
title: Unicode, utf-8, strings and emojis
author: Romain Fran√ßois
date: '2017-08-03'
slug: unicode-utf-8-strings-and-emojis
categories: []
tags:
  - unicode
  - utf8
  - strings
  - emojis
  - utf8splain
  - uni
  - package
  - R
banner: "img/banners/utf8splain.png"
---

```{r echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
```

I've been somewhat obsessing about emojis lately, it all started when I wanted to
check which emojis were used [on twitter](http://romain.rbind.io/blog/2017/07/11/emojis-at-user2017/)
during useR this year.

`r htmltools::HTML("{{< tweet 883199852347367424 >}}")`

But this post is not really about emojis, because my [emojitsu](https://github.com/ThinkRstat/emojitsu)
package is not ready yet, but here's a preview anyway.

`r htmltools::HTML("{{< tweet 892375718247706626 >}}")`

So I'll blog specifically about emojis later, but this has led me to digress down
the üêá hole, because emojis are made of unicode runes typically encoded into utf-8 strings. Most of the
concepts in that last sentence were quite mysterious to me not so long ago, and I believe we should
collectively know more about unicode and utf-8. I learned some of the basics from
the [Strings, bytes, runes and characters in Go](https://blog.golang.org/strings) post in the go
blog, and [The Absolute Minimum Every Software Developer Absolutely, Positively Must Know About Unicode and Character Sets (No Excuses!)](https://www.joelonsoftware.com/2003/10/08/the-absolute-minimum-every-software-developer-absolutely-positively-must-know-about-unicode-and-character-sets-no-excuses/).

Typically when I want to understand something, I make an R package, I guess I really want
to understand this, as I am making not 1, not 2 but 3 packages (if I count `emojitsu`).

 - `uni` : contains a tibble of unicode runes
 - `utf8splain` : to get to the 0 and 1 of utf-8 string encoding
 - `emojitsu` : grammar of emoji, or at least programmatic manipulation of them.

The world has changed now, and strings can no longer be considered as mere sequences of single
characters (bytes). The `uni::code` tibble contains the `r nrow(uni::code)` unicode runes
(aka code points). btw, the generation of the `uni::code` tibble contains some interesting
tidyverse gymnatics, perhaps I'll write another post about that, but let's not digress more yet.

```{r}
uni::code
```

So as of now, unicode has `r nrow(uni::code)` runes, that's way more
than the 256 that can fit into a single byte (8 bits), however we still want to be able to
process text from back in the days when strings were in fact arrays of single bytes.

Unicode is just a giant map of characters, that covers all languages, emojis and other things I don't know
about, currently ranging between `r uni::code$rune[1]` and `r tail(uni::code$rune, 1)`.

```{r}
uni::code %>%
  slice( c(1, n()) )
```

Each rune is just a number, and the job of utf-8 is to encode that number (i.e. its bits) into
a sequence of bytes. To do this utf-8 uses a variable number of bytes.

For each rune:
 - The number of leading 1 in the first byte indicate the number of bytes that the rune need
 - The following bytes all start with "10"
 - All the bits that are not used by this system are used to store the binary representation
  of the rune.

It sounds like a lot of words, so the `utf8splain::runes` function is here to help you.
